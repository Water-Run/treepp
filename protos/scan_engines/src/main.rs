//! æ‰«æå¼•æ“åŸå‹
//!
//! éªŒè¯ walkï¼ˆå•çº¿ç¨‹ï¼‰ä¸ parallelï¼ˆå¤šçº¿ç¨‹ï¼‰ä¸¤ç§ç›®å½•æ‰«ææ¨¡å¼çš„æ­£ç¡®æ€§ä¸ä¸€è‡´æ€§ã€‚
//! æ ¸å¿ƒéªŒè¯ç‚¹ï¼š
//! - ä¸¤ç§æ¨¡å¼äº§ç”Ÿå®Œå…¨ä¸€è‡´çš„ç»“æœ
//! - å¹¶å‘æ‰«æä¸é‡ä¸æ¼
//! - çº¿ç¨‹æ•°å‚æ•°ç”Ÿæ•ˆ
//! - è¾“å‡ºå…·æœ‰ç¡®å®šæ€§æ’åº

use std::cmp::Ordering;
use std::collections::HashMap;
use std::env;
use std::fmt::{self, Display, Formatter};
use std::fs::{self, Metadata};
use std::io;
use std::path::{Path, PathBuf};
use std::process::{Command, Stdio};
use std::sync::atomic::{AtomicUsize, Ordering as AtomicOrdering};
use std::sync::Arc;
use std::time::{Instant, SystemTime};

use crossbeam_channel::{bounded, Sender};
use parking_lot::Mutex;
use rayon::prelude::*;
use rayon::ThreadPoolBuilder;

// ============================================================================
// ç±»å‹å®šä¹‰
// ============================================================================

/// æ–‡ä»¶ç³»ç»Ÿæ¡ç›®ç±»å‹
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum EntryKind {
    /// ç›®å½•
    Directory,
    /// æ–‡ä»¶
    File,
}

/// æ–‡ä»¶ç³»ç»Ÿæ¡ç›®å…ƒæ•°æ®
#[derive(Debug, Clone)]
pub struct EntryMetadata {
    /// æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œç›®å½•ä¸º 0
    pub size: u64,
    /// æœ€åä¿®æ”¹æ—¶é—´
    pub modified: Option<SystemTime>,
    /// åˆ›å»ºæ—¶é—´
    pub created: Option<SystemTime>,
}

impl EntryMetadata {
    fn from_fs_metadata(meta: &Metadata) -> Self {
        Self {
            size: if meta.is_file() { meta.len() } else { 0 },
            modified: meta.modified().ok(),
            created: meta.created().ok(),
        }
    }

    fn empty() -> Self {
        Self {
            size: 0,
            modified: None,
            created: None,
        }
    }
}

/// ç›®å½•æ ‘èŠ‚ç‚¹
#[derive(Debug, Clone)]
pub struct TreeNode {
    /// æ¡ç›®åç§°ï¼ˆä¸å«è·¯å¾„ï¼‰
    pub name: String,
    /// å®Œæ•´è·¯å¾„
    pub path: PathBuf,
    /// æ¡ç›®ç±»å‹
    pub kind: EntryKind,
    /// å…ƒæ•°æ®
    pub metadata: EntryMetadata,
    /// å­èŠ‚ç‚¹ï¼ˆä»…ç›®å½•æœ‰æ•ˆï¼‰
    pub children: Vec<TreeNode>,
}

impl TreeNode {
    /// åˆ›å»ºæ–°èŠ‚ç‚¹
    fn new(path: PathBuf, kind: EntryKind, metadata: EntryMetadata) -> Self {
        let name = path
            .file_name()
            .map(|s| s.to_string_lossy().into_owned())
            .unwrap_or_else(|| path.to_string_lossy().into_owned());

        Self {
            name,
            path,
            kind,
            metadata,
            children: Vec::new(),
        }
    }

    /// é€’å½’ç»Ÿè®¡ç›®å½•æ•°é‡
    pub fn count_directories(&self) -> usize {
        let self_count = if self.kind == EntryKind::Directory {
            1
        } else {
            0
        };
        self_count
            + self
            .children
            .iter()
            .map(TreeNode::count_directories)
            .sum::<usize>()
    }

    /// é€’å½’ç»Ÿè®¡æ–‡ä»¶æ•°é‡
    pub fn count_files(&self) -> usize {
        let self_count = if self.kind == EntryKind::File { 1 } else { 0 };
        self_count
            + self
            .children
            .iter()
            .map(TreeNode::count_files)
            .sum::<usize>()
    }

    /// é€’å½’ç»Ÿè®¡æ€»æ¡ç›®æ•°
    pub fn count_total(&self) -> usize {
        1 + self
            .children
            .iter()
            .map(TreeNode::count_total)
            .sum::<usize>()
    }

    /// è®¡ç®—æœ€å¤§æ·±åº¦
    pub fn max_depth(&self) -> usize {
        if self.children.is_empty() {
            1
        } else {
            1 + self
                .children
                .iter()
                .map(TreeNode::max_depth)
                .max()
                .unwrap_or(0)
        }
    }

    /// å¯¹å­èŠ‚ç‚¹è¿›è¡Œç¡®å®šæ€§æ’åºï¼ˆé€’å½’ï¼‰
    pub fn sort_deterministic(&mut self) {
        self.children.sort_by(|a, b| {
            match (a.kind, b.kind) {
                // ç›®å½•åœ¨å‰ï¼Œæ–‡ä»¶åœ¨å
                (EntryKind::Directory, EntryKind::File) => Ordering::Less,
                (EntryKind::File, EntryKind::Directory) => Ordering::Greater,
                // åŒç±»å‹æŒ‰åç§°å­—å…¸åºï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
                _ => a.name.to_lowercase().cmp(&b.name.to_lowercase()),
            }
        });
        for child in &mut self.children {
            child.sort_deterministic();
        }
    }

    /// æ·±åº¦ç›¸ç­‰æ¯”è¾ƒï¼ˆå¿½ç•¥å…ƒæ•°æ®æ—¶é—´æˆ³çš„å¾®å°å·®å¼‚ï¼‰
    pub fn structural_eq(&self, other: &Self) -> bool {
        if self.name != other.name || self.kind != other.kind {
            return false;
        }
        if self.children.len() != other.children.len() {
            return false;
        }
        self.children
            .iter()
            .zip(other.children.iter())
            .all(|(a, b)| a.structural_eq(b))
    }

    /// æ”¶é›†æ‰€æœ‰è·¯å¾„ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    pub fn collect_paths(&self) -> Vec<PathBuf> {
        let mut paths = vec![self.path.clone()];
        for child in &self.children {
            paths.extend(child.collect_paths());
        }
        paths
    }

    /// æ”¶é›†æ‰€æœ‰åç§°ï¼ˆæ‰å¹³åŒ–ï¼Œç”¨äºå¿«é€Ÿå¯¹æ¯”ï¼‰
    pub fn collect_names(&self) -> Vec<String> {
        let mut names = vec![self.name.clone()];
        for child in &self.children {
            names.extend(child.collect_names());
        }
        names
    }
}

impl Display for TreeNode {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        self.fmt_with_prefix(f, "", true)
    }
}

impl TreeNode {
    fn fmt_with_prefix(&self, f: &mut Formatter<'_>, prefix: &str, is_last: bool) -> fmt::Result {
        let connector = if is_last { "â””â”€" } else { "â”œâ”€" };
        let kind_indicator = match self.kind {
            EntryKind::Directory => "/",
            EntryKind::File => "",
        };

        if prefix.is_empty() {
            writeln!(f, "{}{}", self.name, kind_indicator)?;
        } else {
            writeln!(f, "{}{}{}{}", prefix, connector, self.name, kind_indicator)?;
        }

        let child_prefix = if prefix.is_empty() {
            String::new()
        } else if is_last {
            format!("{}    ", prefix)
        } else {
            format!("{}â”‚   ", prefix)
        };

        let new_prefix = if prefix.is_empty() {
            String::new()
        } else {
            child_prefix
        };

        for (i, child) in self.children.iter().enumerate() {
            let child_is_last = i == self.children.len() - 1;
            child.fmt_with_prefix(f, &new_prefix, child_is_last)?;
        }

        Ok(())
    }
}

/// æ‰«æé…ç½®
#[derive(Debug, Clone)]
pub struct ScanConfig {
    /// æ ¹è·¯å¾„
    pub root: PathBuf,
    /// æ˜¯å¦åŒ…å«æ–‡ä»¶
    pub include_files: bool,
    /// çº¿ç¨‹æ•°ï¼ˆä»… parallel æ¨¡å¼æœ‰æ•ˆï¼‰
    pub thread_count: usize,
}

impl Default for ScanConfig {
    fn default() -> Self {
        Self {
            root: PathBuf::from("."),
            include_files: true,
            thread_count: num_cpus(),
        }
    }
}

/// æ‰«æç»“æœ
#[derive(Debug)]
pub struct ScanResult {
    /// æ ¹èŠ‚ç‚¹
    pub tree: TreeNode,
    /// æ‰«æè€—æ—¶
    pub duration: std::time::Duration,
    /// ç›®å½•æ€»æ•°
    pub directory_count: usize,
    /// æ–‡ä»¶æ€»æ•°
    pub file_count: usize,
}

impl Display for ScanResult {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        writeln!(f, "{}", self.tree)?;
        writeln!(
            f,
            "\n{} ä¸ªç›®å½•, {} ä¸ªæ–‡ä»¶",
            self.directory_count, self.file_count
        )?;
        writeln!(f, "è€—æ—¶: {:.3}s", self.duration.as_secs_f64())
    }
}

// ============================================================================
// å•çº¿ç¨‹æ‰«æå¼•æ“ (walk)
// ============================================================================

/// å•çº¿ç¨‹é€’å½’ç›®å½•æ‰«æ
pub fn scan_walk(config: &ScanConfig) -> io::Result<ScanResult> {
    let start = Instant::now();
    let root_meta = fs::metadata(&config.root)?;
    let root_metadata = EntryMetadata::from_fs_metadata(&root_meta);

    let mut root = TreeNode::new(
        config.root.clone(),
        if root_meta.is_dir() {
            EntryKind::Directory
        } else {
            EntryKind::File
        },
        root_metadata,
    );

    if root.kind == EntryKind::Directory {
        scan_walk_recursive(&config.root, &mut root, config.include_files)?;
    }

    root.sort_deterministic();

    let directory_count = root.count_directories();
    let file_count = root.count_files();
    let duration = start.elapsed();

    Ok(ScanResult {
        tree: root,
        duration,
        directory_count,
        file_count,
    })
}

fn scan_walk_recursive(path: &Path, node: &mut TreeNode, include_files: bool) -> io::Result<()> {
    let entries = match fs::read_dir(path) {
        Ok(entries) => entries,
        Err(_e) => {
            // é™é»˜å¤„ç†æ— æ³•è¯»å–çš„ç›®å½•ï¼ˆæƒé™é—®é¢˜ç­‰ï¼‰
            return Ok(());
        }
    };

    for entry in entries.flatten() {
        let entry_path = entry.path();
        let meta = match entry.metadata() {
            Ok(m) => m,
            Err(_) => continue,
        };

        let kind = if meta.is_dir() {
            EntryKind::Directory
        } else {
            EntryKind::File
        };

        if kind == EntryKind::File && !include_files {
            continue;
        }

        let metadata = EntryMetadata::from_fs_metadata(&meta);
        let mut child = TreeNode::new(entry_path.clone(), kind, metadata);

        if kind == EntryKind::Directory {
            scan_walk_recursive(&entry_path, &mut child, include_files)?;
        }

        node.children.push(child);
    }

    Ok(())
}

// ============================================================================
// å¤šçº¿ç¨‹æ‰«æå¼•æ“ (parallel) - ä½¿ç”¨å·¥ä½œçªƒå–æ¨¡å¼
// ============================================================================

/// ä¸­é—´æ‰«æç»“æœï¼ˆæ‰å¹³åŒ–ï¼‰
#[derive(Debug, Clone)]
struct FlatEntry {
    path: PathBuf,
    parent: PathBuf,
    kind: EntryKind,
    metadata: EntryMetadata,
}

/// å¤šçº¿ç¨‹å¹¶å‘ç›®å½•æ‰«æï¼ˆä½¿ç”¨ rayon å·¥ä½œçªƒå–ï¼‰
pub fn scan_parallel(config: &ScanConfig) -> io::Result<ScanResult> {
    let start = Instant::now();
    let root_meta = fs::metadata(&config.root)?;

    if !root_meta.is_dir() {
        return scan_walk(config);
    }

    // åˆ›å»ºè‡ªå®šä¹‰çº¿ç¨‹æ± 
    let pool = ThreadPoolBuilder::new()
        .num_threads(config.thread_count)
        .build()
        .map_err(|e| io::Error::new(io::ErrorKind::Other, e))?;

    let root_path = config.root.clone();
    let include_files = config.include_files;

    // ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œæ‰«æ
    let flat_entries = pool.install(|| {
        let entries = Arc::new(Mutex::new(Vec::new()));

        // æ·»åŠ æ ¹ç›®å½•
        let root_metadata = EntryMetadata::from_fs_metadata(&root_meta);
        entries.lock().push(FlatEntry {
            path: root_path.clone(),
            parent: PathBuf::new(),
            kind: EntryKind::Directory,
            metadata: root_metadata,
        });

        // é€’å½’æ‰«æ
        scan_directory_parallel(&root_path, &root_path, include_files, &entries);

        Arc::try_unwrap(entries)
            .map(|m| m.into_inner())
            .unwrap_or_default()
    });

    let tree = build_tree_from_flat(&config.root, flat_entries);

    let mut tree = tree.unwrap_or_else(|| {
        TreeNode::new(
            config.root.clone(),
            EntryKind::Directory,
            EntryMetadata::empty(),
        )
    });

    tree.sort_deterministic();

    let directory_count = tree.count_directories();
    let file_count = tree.count_files();
    let duration = start.elapsed();

    Ok(ScanResult {
        tree,
        duration,
        directory_count,
        file_count,
    })
}

fn scan_directory_parallel(
    path: &Path,
    root: &Path,
    include_files: bool,
    entries: &Arc<Mutex<Vec<FlatEntry>>>,
) {
    let dir_entries: Vec<_> = match fs::read_dir(path) {
        Ok(entries) => entries.flatten().collect(),
        Err(_) => return,
    };

    // åˆ†ç¦»ç›®å½•å’Œæ–‡ä»¶
    let mut subdirs = Vec::new();
    let mut local_entries = Vec::new();

    for entry in dir_entries {
        let entry_path = entry.path();
        let meta = match entry.metadata() {
            Ok(m) => m,
            Err(_) => continue,
        };

        let kind = if meta.is_dir() {
            EntryKind::Directory
        } else {
            EntryKind::File
        };

        if kind == EntryKind::File && !include_files {
            continue;
        }

        let metadata = EntryMetadata::from_fs_metadata(&meta);
        local_entries.push(FlatEntry {
            path: entry_path.clone(),
            parent: path.to_path_buf(),
            kind,
            metadata,
        });

        if kind == EntryKind::Directory {
            subdirs.push(entry_path);
        }
    }

    // æ‰¹é‡æ·»åŠ æ¡ç›®
    {
        let mut guard = entries.lock();
        guard.extend(local_entries);
    }

    // ä½¿ç”¨ rayon å¹¶è¡Œå¤„ç†å­ç›®å½•
    subdirs.par_iter().for_each(|subdir| {
        scan_directory_parallel(subdir, root, include_files, entries);
    });
}

/// å¤šçº¿ç¨‹å¹¶å‘ç›®å½•æ‰«æï¼ˆä½¿ç”¨é€šé“æ¨¡å¼ï¼‰- å¤‡ç”¨å®ç°
pub fn scan_parallel_channel(config: &ScanConfig) -> io::Result<ScanResult> {
    let start = Instant::now();
    let root_meta = fs::metadata(&config.root)?;

    if !root_meta.is_dir() {
        return scan_walk(config);
    }

    let thread_count = config.thread_count;
    let (task_tx, task_rx) = bounded::<PathBuf>(thread_count * 64);
    let (result_tx, result_rx) = bounded::<FlatEntry>(thread_count * 256);

    let pending = Arc::new(AtomicUsize::new(1));
    let include_files = config.include_files;

    // å‘é€æ ¹ç›®å½•ä»»åŠ¡
    task_tx.send(config.root.clone()).unwrap();

    // å‘é€æ ¹ç›®å½•æ¡ç›®
    let root_metadata = EntryMetadata::from_fs_metadata(&root_meta);
    result_tx
        .send(FlatEntry {
            path: config.root.clone(),
            parent: PathBuf::new(),
            kind: EntryKind::Directory,
            metadata: root_metadata,
        })
        .unwrap();

    // å¯åŠ¨å·¥ä½œçº¿ç¨‹
    let workers: Vec<_> = (0..thread_count)
        .map(|_| {
            let task_rx = task_rx.clone();
            let task_tx = task_tx.clone();
            let result_tx = result_tx.clone();
            let pending = Arc::clone(&pending);

            std::thread::spawn(move || {
                worker_loop(task_rx, task_tx, result_tx, pending, include_files);
            })
        })
        .collect();

    // å…³é—­å‘é€ç«¯ï¼ˆå·¥ä½œçº¿ç¨‹æœ‰è‡ªå·±çš„å…‹éš†ï¼‰
    drop(task_tx);
    drop(result_tx);

    // æ”¶é›†ç»“æœ
    let flat_entries: Vec<FlatEntry> = result_rx.iter().collect();

    // ç­‰å¾…æ‰€æœ‰å·¥ä½œçº¿ç¨‹å®Œæˆ
    for worker in workers {
        let _ = worker.join();
    }

    let tree = build_tree_from_flat(&config.root, flat_entries);

    let mut tree = tree.unwrap_or_else(|| {
        TreeNode::new(
            config.root.clone(),
            EntryKind::Directory,
            EntryMetadata::empty(),
        )
    });

    tree.sort_deterministic();

    let directory_count = tree.count_directories();
    let file_count = tree.count_files();
    let duration = start.elapsed();

    Ok(ScanResult {
        tree,
        duration,
        directory_count,
        file_count,
    })
}

fn worker_loop(
    task_rx: crossbeam_channel::Receiver<PathBuf>,
    task_tx: Sender<PathBuf>,
    result_tx: Sender<FlatEntry>,
    pending: Arc<AtomicUsize>,
    include_files: bool,
) {
    loop {
        match task_rx.recv_timeout(std::time::Duration::from_millis(10)) {
            Ok(dir_path) => {
                process_directory(&dir_path, &task_tx, &result_tx, &pending, include_files);

                // ä»»åŠ¡å®Œæˆï¼Œå‡å°‘è®¡æ•°
                let prev = pending.fetch_sub(1, AtomicOrdering::SeqCst);
                if prev == 1 {
                    // æœ€åä¸€ä¸ªä»»åŠ¡å®Œæˆï¼Œé€€å‡º
                    break;
                }
            }
            Err(crossbeam_channel::RecvTimeoutError::Timeout) => {
                // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
                if pending.load(AtomicOrdering::SeqCst) == 0 {
                    break;
                }
            }
            Err(crossbeam_channel::RecvTimeoutError::Disconnected) => {
                break;
            }
        }
    }
}

fn process_directory(
    dir_path: &Path,
    task_tx: &Sender<PathBuf>,
    result_tx: &Sender<FlatEntry>,
    pending: &Arc<AtomicUsize>,
    include_files: bool,
) {
    let dir_entries = match fs::read_dir(dir_path) {
        Ok(entries) => entries,
        Err(_) => return,
    };

    let mut subdirs = Vec::new();

    for entry in dir_entries.flatten() {
        let entry_path = entry.path();
        let meta = match entry.metadata() {
            Ok(m) => m,
            Err(_) => continue,
        };

        let kind = if meta.is_dir() {
            EntryKind::Directory
        } else {
            EntryKind::File
        };

        if kind == EntryKind::File && !include_files {
            continue;
        }

        let metadata = EntryMetadata::from_fs_metadata(&meta);
        let _ = result_tx.send(FlatEntry {
            path: entry_path.clone(),
            parent: dir_path.to_path_buf(),
            kind,
            metadata,
        });

        if kind == EntryKind::Directory {
            subdirs.push(entry_path);
        }
    }

    // å¢åŠ å¾…å¤„ç†è®¡æ•°å¹¶å‘é€å­ç›®å½•ä»»åŠ¡
    if !subdirs.is_empty() {
        pending.fetch_add(subdirs.len(), AtomicOrdering::SeqCst);
        for subdir in subdirs {
            let _ = task_tx.send(subdir);
        }
    }
}

fn build_tree_from_flat(root: &Path, entries: Vec<FlatEntry>) -> Option<TreeNode> {
    let mut node_map: HashMap<PathBuf, TreeNode> = HashMap::with_capacity(entries.len());
    let mut root_node: Option<TreeNode> = None;

    for entry in &entries {
        let node = TreeNode::new(entry.path.clone(), entry.kind, entry.metadata.clone());
        if entry.path == root {
            root_node = Some(node);
        } else {
            node_map.insert(entry.path.clone(), node);
        }
    }

    let mut children_map: HashMap<PathBuf, Vec<PathBuf>> = HashMap::new();
    for entry in &entries {
        if entry.path != root {
            children_map
                .entry(entry.parent.clone())
                .or_default()
                .push(entry.path.clone());
        }
    }

    fn attach_children(
        node: &mut TreeNode,
        children_map: &HashMap<PathBuf, Vec<PathBuf>>,
        node_map: &mut HashMap<PathBuf, TreeNode>,
    ) {
        if let Some(child_paths) = children_map.get(&node.path) {
            for child_path in child_paths {
                if let Some(mut child) = node_map.remove(child_path) {
                    attach_children(&mut child, children_map, node_map);
                    node.children.push(child);
                }
            }
        }
    }

    if let Some(ref mut root) = root_node {
        attach_children(root, &children_map, &mut node_map);
    }

    root_node
}

// ============================================================================
// åŸç”Ÿ tree å‘½ä»¤è°ƒç”¨
// ============================================================================

/// è°ƒç”¨ Windows åŸç”Ÿ tree å‘½ä»¤å¹¶è§£æè¾“å‡º
pub fn scan_native_tree(path: &Path, include_files: bool) -> io::Result<NativeTreeResult> {
    let start = Instant::now();

    let mut cmd = Command::new("cmd");
    cmd.args(["/C", "tree"]);

    if include_files {
        cmd.arg("/F");
    }

    cmd.arg(path);
    cmd.stdout(Stdio::piped());
    cmd.stderr(Stdio::null());

    let output = cmd.output()?;
    let duration = start.elapsed();

    let stdout = String::from_utf8_lossy(&output.stdout);
    let lines: Vec<String> = stdout.lines().map(String::from).collect();

    let (directory_count, file_count) = parse_native_tree_stats(&lines);

    Ok(NativeTreeResult {
        lines,
        duration,
        directory_count,
        file_count,
    })
}

/// åŸç”Ÿ tree å‘½ä»¤ç»“æœ
#[derive(Debug)]
pub struct NativeTreeResult {
    /// è¾“å‡ºè¡Œ
    pub lines: Vec<String>,
    /// æ‰§è¡Œè€—æ—¶
    pub duration: std::time::Duration,
    /// ç›®å½•æ•°é‡ï¼ˆè§£æå¾—åˆ°ï¼‰
    pub directory_count: usize,
    /// æ–‡ä»¶æ•°é‡ï¼ˆè§£æå¾—åˆ°ï¼‰
    pub file_count: usize,
}

fn parse_native_tree_stats(lines: &[String]) -> (usize, usize) {
    for line in lines.iter().rev() {
        if line.contains("ä¸ªç›®å½•") || line.contains("ä¸ªæ–‡ä»¶") {
            let parts: Vec<&str> = line.split_whitespace().collect();
            let mut dirs = 0usize;
            let mut files = 0usize;

            for (i, part) in parts.iter().enumerate() {
                if *part == "ä¸ªç›®å½•" || part.contains("ä¸ªç›®å½•") {
                    if i > 0 {
                        dirs = parts[i - 1].parse().unwrap_or(0);
                    }
                }
                if *part == "ä¸ªæ–‡ä»¶" || part.contains("ä¸ªæ–‡ä»¶") {
                    if i > 0 {
                        files = parts[i - 1].parse().unwrap_or(0);
                    }
                }
            }

            return (dirs, files);
        }
    }
    (0, 0)
}

// ============================================================================
// è¾…åŠ©å‡½æ•°
// ============================================================================

fn num_cpus() -> usize {
    std::thread::available_parallelism()
        .map(|n| n.get())
        .unwrap_or(4)
}

/// éªŒè¯ä¸¤ä¸ªæ‰«æç»“æœçš„ç»“æ„ä¸€è‡´æ€§
pub fn verify_consistency(walk: &ScanResult, parallel: &ScanResult) -> ConsistencyReport {
    let walk_paths = walk.tree.collect_paths();
    let parallel_paths = parallel.tree.collect_paths();

    let structural_match = walk.tree.structural_eq(&parallel.tree);

    let walk_set: std::collections::HashSet<_> = walk_paths.iter().collect();
    let parallel_set: std::collections::HashSet<_> = parallel_paths.iter().collect();

    let only_in_walk: Vec<_> = walk_set.difference(&parallel_set).cloned().collect();
    let only_in_parallel: Vec<_> = parallel_set.difference(&walk_set).cloned().collect();

    ConsistencyReport {
        structural_match,
        walk_count: walk_paths.len(),
        parallel_count: parallel_paths.len(),
        only_in_walk: only_in_walk.into_iter().cloned().collect(),
        only_in_parallel: only_in_parallel.into_iter().cloned().collect(),
        directory_count_match: walk.directory_count == parallel.directory_count,
        file_count_match: walk.file_count == parallel.file_count,
    }
}

/// ä¸€è‡´æ€§éªŒè¯æŠ¥å‘Š
#[derive(Debug)]
pub struct ConsistencyReport {
    /// ç»“æ„æ˜¯å¦å®Œå…¨åŒ¹é…
    pub structural_match: bool,
    /// walk æ¨¡å¼æ¡ç›®æ•°
    pub walk_count: usize,
    /// parallel æ¨¡å¼æ¡ç›®æ•°
    pub parallel_count: usize,
    /// ä»…åœ¨ walk ç»“æœä¸­çš„è·¯å¾„
    pub only_in_walk: Vec<PathBuf>,
    /// ä»…åœ¨ parallel ç»“æœä¸­çš„è·¯å¾„
    pub only_in_parallel: Vec<PathBuf>,
    /// ç›®å½•æ•°é‡æ˜¯å¦åŒ¹é…
    pub directory_count_match: bool,
    /// æ–‡ä»¶æ•°é‡æ˜¯å¦åŒ¹é…
    pub file_count_match: bool,
}

impl ConsistencyReport {
    pub fn is_consistent(&self) -> bool {
        self.structural_match
            && self.only_in_walk.is_empty()
            && self.only_in_parallel.is_empty()
            && self.directory_count_match
            && self.file_count_match
    }
}

impl Display for ConsistencyReport {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        writeln!(f, "=== ä¸€è‡´æ€§éªŒè¯æŠ¥å‘Š ===")?;
        writeln!(
            f,
            "ç»“æ„åŒ¹é…: {}",
            if self.structural_match { "âœ“" } else { "âœ—" }
        )?;
        writeln!(f, "walk æ¡ç›®æ•°: {}", self.walk_count)?;
        writeln!(f, "parallel æ¡ç›®æ•°: {}", self.parallel_count)?;
        writeln!(
            f,
            "ç›®å½•æ•°é‡åŒ¹é…: {}",
            if self.directory_count_match {
                "âœ“"
            } else {
                "âœ—"
            }
        )?;
        writeln!(
            f,
            "æ–‡ä»¶æ•°é‡åŒ¹é…: {}",
            if self.file_count_match { "âœ“" } else { "âœ—" }
        )?;

        if !self.only_in_walk.is_empty() {
            writeln!(f, "\nä»…åœ¨ walk ç»“æœä¸­:")?;
            for p in &self.only_in_walk {
                writeln!(f, "  - {:?}", p)?;
            }
        }

        if !self.only_in_parallel.is_empty() {
            writeln!(f, "\nä»…åœ¨ parallel ç»“æœä¸­:")?;
            for p in &self.only_in_parallel {
                writeln!(f, "  - {:?}", p)?;
            }
        }

        writeln!(
            f,
            "\næ€»ä½“ç»“è®º: {}",
            if self.is_consistent() {
                "ä¸€è‡´ âœ“"
            } else {
                "ä¸ä¸€è‡´ âœ—"
            }
        )
    }
}

// ============================================================================
// ä¸»ç¨‹åºå…¥å£
// ============================================================================

fn main() -> io::Result<()> {
    let args: Vec<String> = env::args().collect();

    let path = if args.len() > 1 {
        PathBuf::from(&args[1])
    } else {
        env::current_dir()?
    };

    let thread_count = args
        .iter()
        .position(|a| a == "-t" || a == "--threads")
        .and_then(|i| args.get(i + 1))
        .and_then(|s| s.parse().ok())
        .unwrap_or_else(num_cpus);

    let include_files = args
        .iter()
        .any(|a| a == "-f" || a == "--files" || a == "/F");

    println!("æ‰«æç›®å½•: {:?}", path);
    println!("çº¿ç¨‹æ•°: {}", thread_count);
    println!("åŒ…å«æ–‡ä»¶: {}", include_files);
    println!();

    let config = ScanConfig {
        root: path.clone(),
        include_files,
        thread_count,
    };

    println!("=== Walk æ¨¡å¼ (å•çº¿ç¨‹) ===");
    let walk_result = scan_walk(&config)?;
    println!(
        "ç›®å½•: {}, æ–‡ä»¶: {}, è€—æ—¶: {:.3}s",
        walk_result.directory_count,
        walk_result.file_count,
        walk_result.duration.as_secs_f64()
    );

    println!("\n=== Parallel æ¨¡å¼ ({}çº¿ç¨‹, rayon) ===", thread_count);
    let parallel_result = scan_parallel(&config)?;
    println!(
        "ç›®å½•: {}, æ–‡ä»¶: {}, è€—æ—¶: {:.3}s",
        parallel_result.directory_count,
        parallel_result.file_count,
        parallel_result.duration.as_secs_f64()
    );

    println!("\n=== Parallel æ¨¡å¼ ({}çº¿ç¨‹, channel) ===", thread_count);
    let parallel_channel_result = scan_parallel_channel(&config)?;
    println!(
        "ç›®å½•: {}, æ–‡ä»¶: {}, è€—æ—¶: {:.3}s",
        parallel_channel_result.directory_count,
        parallel_channel_result.file_count,
        parallel_channel_result.duration.as_secs_f64()
    );

    println!("\n=== ä¸€è‡´æ€§éªŒè¯ ===");
    let report = verify_consistency(&walk_result, &parallel_result);
    println!("{}", report);

    if include_files {
        println!("\n=== åŸç”Ÿ tree å‘½ä»¤å¯¹æ¯” ===");
        match scan_native_tree(&path, include_files) {
            Ok(native) => {
                println!(
                    "åŸç”Ÿ tree: ç›®å½• {}, æ–‡ä»¶ {}, è€—æ—¶: {:.3}s",
                    native.directory_count,
                    native.file_count,
                    native.duration.as_secs_f64()
                );

                let speedup_walk =
                    native.duration.as_secs_f64() / walk_result.duration.as_secs_f64();
                let speedup_parallel =
                    native.duration.as_secs_f64() / parallel_result.duration.as_secs_f64();

                println!("\næ€§èƒ½å¯¹æ¯”:");
                println!("  walk vs native: {:.2}x", speedup_walk);
                println!("  parallel vs native: {:.2}x", speedup_parallel);
            }
            Err(e) => {
                println!("æ— æ³•æ‰§è¡ŒåŸç”Ÿ tree å‘½ä»¤: {}", e);
            }
        }
    }

    Ok(())
}

// ============================================================================
// å•å…ƒæµ‹è¯•
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::{self, File};
    use std::io::Write;
    use tempfile::TempDir;

    // ========================================================================
    // æµ‹è¯•è¾…åŠ©å‡½æ•°
    // ========================================================================

    /// åˆ›å»ºæµ‹è¯•ç”¨ä¸´æ—¶ç›®å½•ç»“æ„
    fn create_test_directory() -> TempDir {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let root = temp.path();

        fs::create_dir_all(root.join("src/utils")).unwrap();
        fs::create_dir_all(root.join("tests")).unwrap();
        fs::create_dir_all(root.join("docs/api")).unwrap();
        fs::create_dir(root.join("empty_dir")).unwrap();

        File::create(root.join("Cargo.toml")).unwrap();
        File::create(root.join("README.md")).unwrap();
        File::create(root.join("src/main.rs")).unwrap();
        File::create(root.join("src/lib.rs")).unwrap();
        File::create(root.join("src/utils/helper.rs")).unwrap();
        File::create(root.join("tests/integration.rs")).unwrap();
        File::create(root.join("docs/api/index.html")).unwrap();

        temp
    }

    /// åˆ›å»ºæ·±å±‚åµŒå¥—ç›®å½•ç»“æ„
    fn create_deep_directory(depth: usize) -> TempDir {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let mut current = temp.path().to_path_buf();

        for i in 0..depth {
            current = current.join(format!("level_{}", i));
            fs::create_dir(&current).unwrap();
            File::create(current.join(format!("file_{}.txt", i))).unwrap();
        }

        temp
    }

    /// åˆ›å»ºå®½ç›®å½•ç»“æ„ï¼ˆå•å±‚å¤šæ–‡ä»¶ï¼‰
    fn create_wide_directory(width: usize) -> TempDir {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let root = temp.path();

        for i in 0..width {
            File::create(root.join(format!("file_{:04}.txt", i))).unwrap();
        }

        for i in 0..width / 10 {
            fs::create_dir(root.join(format!("dir_{:04}", i))).unwrap();
        }

        temp
    }

    /// åˆ›å»ºæ··åˆç›®å½•ç»“æ„
    fn create_mixed_directory() -> TempDir {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let root = temp.path();

        // å¤šå±‚ç›®å½•
        for i in 0..5 {
            let dir = root.join(format!("dir_{}", i));
            fs::create_dir_all(&dir).unwrap();

            for j in 0..3 {
                File::create(dir.join(format!("file_{}.txt", j))).unwrap();
                let subdir = dir.join(format!("subdir_{}", j));
                fs::create_dir(&subdir).unwrap();
                File::create(subdir.join("nested.txt")).unwrap();
            }
        }

        temp
    }

    /// åˆ›å»ºå¸¦æœ‰å¤§æ–‡ä»¶çš„ç›®å½•
    fn create_directory_with_sizes() -> TempDir {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let root = temp.path();

        let mut small = File::create(root.join("small.txt")).unwrap();
        small.write_all(b"small").unwrap();

        let mut medium = File::create(root.join("medium.txt")).unwrap();
        medium.write_all(&vec![0u8; 1024]).unwrap();

        let mut large = File::create(root.join("large.txt")).unwrap();
        large.write_all(&vec![0u8; 10240]).unwrap();

        temp
    }

    // ========================================================================
    // åŸºç¡€åŠŸèƒ½æµ‹è¯• (6 tests)
    // ========================================================================

    #[test]
    fn test_walk_basic() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 1,
        };

        let result = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");

        assert_eq!(result.tree.kind, EntryKind::Directory);
        assert!(result.directory_count > 0);
        assert!(result.file_count > 0);
    }

    #[test]
    fn test_parallel_basic() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let result = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        assert_eq!(result.tree.kind, EntryKind::Directory);
        assert!(result.directory_count > 0);
        assert!(result.file_count > 0);
    }

    #[test]
    fn test_parallel_channel_basic() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let result = scan_parallel_channel(&config).expect("parallel_channel æ‰«æå¤±è´¥");

        assert_eq!(result.tree.kind, EntryKind::Directory);
        assert!(result.directory_count > 0);
        assert!(result.file_count > 0);
    }

    #[test]
    fn test_walk_without_files() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: false,
            thread_count: 1,
        };

        let result = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");

        assert_eq!(result.file_count, 0);
        assert!(result.directory_count > 0);
    }

    #[test]
    fn test_parallel_without_files() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: false,
            thread_count: 4,
        };

        let result = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        assert_eq!(result.file_count, 0);
        assert!(result.directory_count > 0);
    }

    #[test]
    fn test_scan_single_file() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let file_path = temp.path().join("single.txt");
        File::create(&file_path).unwrap();

        let config = ScanConfig {
            root: file_path,
            include_files: true,
            thread_count: 1,
        };

        let result = scan_walk(&config).expect("æ‰«æå¤±è´¥");
        assert_eq!(result.tree.kind, EntryKind::File);
        assert_eq!(result.file_count, 1);
        assert_eq!(result.directory_count, 0);
    }

    // ========================================================================
    // ä¸€è‡´æ€§æµ‹è¯• (8 tests)
    // ========================================================================

    #[test]
    fn test_consistency_with_files() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(report.is_consistent(), "ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}", report);
    }

    #[test]
    fn test_consistency_without_files() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: false,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(report.is_consistent(), "ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}", report);
    }

    #[test]
    fn test_consistency_deep_directory() {
        let temp = create_deep_directory(20);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 8,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(
            report.is_consistent(),
            "æ·±å±‚ç›®å½•ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}",
            report
        );
    }

    #[test]
    fn test_consistency_wide_directory() {
        let temp = create_wide_directory(100);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 8,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(
            report.is_consistent(),
            "å®½ç›®å½•ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}",
            report
        );
    }

    #[test]
    fn test_consistency_mixed_directory() {
        let temp = create_mixed_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(
            report.is_consistent(),
            "æ··åˆç›®å½•ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}",
            report
        );
    }

    #[test]
    fn test_consistency_channel_vs_rayon() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let rayon = scan_parallel(&config).expect("rayon æ‰«æå¤±è´¥");
        let channel = scan_parallel_channel(&config).expect("channel æ‰«æå¤±è´¥");

        let report = verify_consistency(&rayon, &channel);
        assert!(
            report.is_consistent(),
            "rayon ä¸ channel å®ç°ä¸ä¸€è‡´:\n{}",
            report
        );
    }

    #[test]
    fn test_consistency_multiple_runs() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let results: Vec<_> = (0..5)
            .map(|_| scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥"))
            .collect();

        for i in 1..results.len() {
            let report = verify_consistency(&results[0], &results[i]);
            assert!(
                report.is_consistent(),
                "ç¬¬ {} æ¬¡è¿è¡Œä¸ç¬¬ 0 æ¬¡è¿è¡Œä¸ä¸€è‡´:\n{}",
                i,
                report
            );
        }
    }

    #[test]
    fn test_consistency_all_three_methods() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");
        let channel = scan_parallel_channel(&config).expect("channel æ‰«æå¤±è´¥");

        assert!(verify_consistency(&walk, &parallel).is_consistent());
        assert!(verify_consistency(&walk, &channel).is_consistent());
        assert!(verify_consistency(&parallel, &channel).is_consistent());
    }

    // ========================================================================
    // çº¿ç¨‹æ•°éªŒè¯æµ‹è¯• (4 tests)
    // ========================================================================

    #[test]
    fn test_thread_count_variations() {
        let temp = create_wide_directory(50);

        for thread_count in [1, 2, 4, 8] {
            let config = ScanConfig {
                root: temp.path().to_path_buf(),
                include_files: true,
                thread_count,
            };

            let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
            let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

            let report = verify_consistency(&walk, &parallel);
            assert!(
                report.is_consistent(),
                "çº¿ç¨‹æ•° {} æ—¶ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}",
                thread_count,
                report
            );
        }
    }

    #[test]
    fn test_single_thread_parallel() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 1,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(
            report.is_consistent(),
            "å•çº¿ç¨‹ parallel ä¸ walk ä¸ä¸€è‡´:\n{}",
            report
        );
    }

    #[test]
    fn test_many_threads() {
        let temp = create_wide_directory(100);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 32,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(report.is_consistent(), "é«˜çº¿ç¨‹æ•°ä¸ä¸€è‡´:\n{}", report);
    }

    #[test]
    fn test_thread_count_channel_variations() {
        let temp = create_test_directory();

        for thread_count in [1, 2, 4] {
            let config = ScanConfig {
                root: temp.path().to_path_buf(),
                include_files: true,
                thread_count,
            };

            let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
            let channel = scan_parallel_channel(&config).expect("channel æ‰«æå¤±è´¥");

            let report = verify_consistency(&walk, &channel);
            assert!(
                report.is_consistent(),
                "channel æ¨¡å¼çº¿ç¨‹æ•° {} æ—¶ä¸ä¸€è‡´:\n{}",
                thread_count,
                report
            );
        }
    }

    // ========================================================================
    // è¾¹ç•Œæƒ…å†µæµ‹è¯• (8 tests)
    // ========================================================================

    #[test]
    fn test_empty_directory() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        assert_eq!(walk.file_count, 0);
        assert_eq!(parallel.file_count, 0);
        assert_eq!(walk.directory_count, 1);
        assert_eq!(parallel.directory_count, 1);
    }

    #[test]
    fn test_single_file_directory() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        File::create(temp.path().join("single.txt")).unwrap();

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        assert_eq!(walk.file_count, 1);
        assert_eq!(parallel.file_count, 1);

        let report = verify_consistency(&walk, &parallel);
        assert!(report.is_consistent());
    }

    #[test]
    fn test_deeply_nested_single_file() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        let deep_path = temp.path().join("a/b/c/d/e/f/g/h/i/j");
        fs::create_dir_all(&deep_path).unwrap();
        File::create(deep_path.join("deep.txt")).unwrap();

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(
            report.is_consistent(),
            "æ·±å±‚åµŒå¥—å•æ–‡ä»¶ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}",
            report
        );
    }

    #[test]
    fn test_special_characters_in_names() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");

        let special_names = ["æ–‡ä»¶å¤¹", "folder with spaces", "folder-with-dashes"];

        for name in &special_names {
            fs::create_dir(temp.path().join(name)).unwrap();
            File::create(temp.path().join(format!("{}.txt", name))).unwrap();
        }

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(
            report.is_consistent(),
            "ç‰¹æ®Šå­—ç¬¦åç§°ä¸€è‡´æ€§éªŒè¯å¤±è´¥:\n{}",
            report
        );
    }

    #[test]
    fn test_unicode_names() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");

        let unicode_names = ["æ—¥æœ¬èª", "í•œêµ­ì–´", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "ğŸ‰ğŸŠ"];

        for name in &unicode_names {
            if fs::create_dir(temp.path().join(name)).is_ok() {
                let _ = File::create(temp.path().join(format!("{}.txt", name)));
            }
        }

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        let report = verify_consistency(&walk, &parallel);
        assert!(report.is_consistent(), "Unicode åç§°ä¸ä¸€è‡´:\n{}", report);
    }

    #[test]
    fn test_symlinks_ignored() {
        // ç¬¦å·é“¾æ¥åœ¨ Windows ä¸Šéœ€è¦ç‰¹æ®Šæƒé™ï¼Œæ­¤æµ‹è¯•éªŒè¯ä¸å´©æºƒå³å¯
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let _ = scan_walk(&config);
        let _ = scan_parallel(&config);
    }

    #[test]
    fn test_many_empty_subdirs() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");

        for i in 0..50 {
            fs::create_dir(temp.path().join(format!("empty_{}", i))).unwrap();
        }

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");

        assert_eq!(walk.directory_count, 51); // root + 50
        assert_eq!(parallel.directory_count, 51);
        assert!(verify_consistency(&walk, &parallel).is_consistent());
    }

    #[test]
    fn test_file_sizes() {
        let temp = create_directory_with_sizes();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let result = scan_walk(&config).expect("æ‰«æå¤±è´¥");

        let sizes: Vec<_> = result
            .tree
            .children
            .iter()
            .map(|c| (&c.name, c.metadata.size))
            .collect();

        assert!(sizes.iter().any(|(n, s)| n.contains("small") && *s == 5));
        assert!(sizes.iter().any(|(n, s)| n.contains("medium") && *s == 1024));
        assert!(sizes
            .iter()
            .any(|(n, s)| n.contains("large") && *s == 10240));
    }

    // ========================================================================
    // æ’åºç¡®å®šæ€§æµ‹è¯• (4 tests)
    // ========================================================================

    #[test]
    fn test_deterministic_ordering() {
        let temp = create_wide_directory(30);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 8,
        };

        let results: Vec<_> = (0..10)
            .map(|_| {
                let result = scan_parallel(&config).expect("æ‰«æå¤±è´¥");
                result.tree.collect_paths()
            })
            .collect();

        for i in 1..results.len() {
            assert_eq!(
                results[0], results[i],
                "ç¬¬ {} æ¬¡è¿è¡Œçš„è·¯å¾„é¡ºåºä¸ç¬¬ 0 æ¬¡ä¸åŒ",
                i
            );
        }
    }

    #[test]
    fn test_sort_directories_before_files() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");

        File::create(temp.path().join("aaa.txt")).unwrap();
        fs::create_dir(temp.path().join("zzz")).unwrap();
        File::create(temp.path().join("bbb.txt")).unwrap();
        fs::create_dir(temp.path().join("aaa_dir")).unwrap();

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let result = scan_parallel(&config).expect("æ‰«æå¤±è´¥");

        let children = &result.tree.children;
        let first_file_idx = children
            .iter()
            .position(|c| c.kind == EntryKind::File)
            .unwrap_or(children.len());
        let last_dir_idx = children
            .iter()
            .rposition(|c| c.kind == EntryKind::Directory)
            .unwrap_or(0);

        assert!(
            last_dir_idx < first_file_idx || first_file_idx == children.len(),
            "ç›®å½•åº”è¯¥æ’åœ¨æ–‡ä»¶ä¹‹å‰"
        );
    }

    #[test]
    fn test_case_insensitive_sort() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");

        File::create(temp.path().join("Apple.txt")).unwrap();
        File::create(temp.path().join("banana.txt")).unwrap();
        File::create(temp.path().join("CHERRY.txt")).unwrap();
        File::create(temp.path().join("date.txt")).unwrap();

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let result = scan_parallel(&config).expect("æ‰«æå¤±è´¥");
        let names: Vec<_> = result
            .tree
            .children
            .iter()
            .map(|c| c.name.clone())
            .collect();

        // éªŒè¯å¤§å°å†™ä¸æ•æ„Ÿæ’åº
        assert_eq!(names[0].to_lowercase(), "apple.txt");
        assert_eq!(names[1].to_lowercase(), "banana.txt");
        assert_eq!(names[2].to_lowercase(), "cherry.txt");
        assert_eq!(names[3].to_lowercase(), "date.txt");
    }

    #[test]
    fn test_channel_deterministic_ordering() {
        let temp = create_wide_directory(30);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let results: Vec<_> = (0..5)
            .map(|_| {
                let result = scan_parallel_channel(&config).expect("æ‰«æå¤±è´¥");
                result.tree.collect_paths()
            })
            .collect();

        for i in 1..results.len() {
            assert_eq!(results[0], results[i], "channel æ¨¡å¼æ’åºä¸ç¡®å®š");
        }
    }

    // ========================================================================
    // TreeNode æ–¹æ³•æµ‹è¯• (4 tests)
    // ========================================================================

    #[test]
    fn test_tree_node_count_total() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 1,
        };

        let result = scan_walk(&config).expect("æ‰«æå¤±è´¥");
        let total = result.tree.count_total();

        assert_eq!(
            total,
            result.directory_count + result.file_count,
            "count_total åº”ç­‰äºç›®å½•æ•° + æ–‡ä»¶æ•°"
        );
    }

    #[test]
    fn test_tree_node_max_depth() {
        let temp = create_deep_directory(10);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 1,
        };

        let result = scan_walk(&config).expect("æ‰«æå¤±è´¥");
        let depth = result.tree.max_depth();

        assert_eq!(depth, 11, "æ·±åº¦åº”ä¸º 11 (æ ¹ + 10 å±‚)");
    }

    #[test]
    fn test_tree_node_collect_names() {
        let temp = TempDir::new().expect("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥");
        File::create(temp.path().join("a.txt")).unwrap();
        File::create(temp.path().join("b.txt")).unwrap();
        fs::create_dir(temp.path().join("c")).unwrap();

        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 1,
        };

        let result = scan_walk(&config).expect("æ‰«æå¤±è´¥");
        let names = result.tree.collect_names();

        assert_eq!(names.len(), 4); // root + 3 entries
        assert!(names.contains(&"a.txt".to_string()));
        assert!(names.contains(&"b.txt".to_string()));
        assert!(names.contains(&"c".to_string()));
    }

    #[test]
    fn test_tree_node_structural_eq() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 1,
        };

        let result1 = scan_walk(&config).expect("æ‰«æå¤±è´¥");
        let result2 = scan_walk(&config).expect("æ‰«æå¤±è´¥");

        assert!(result1.tree.structural_eq(&result2.tree));
    }

    // ========================================================================
    // æ€§èƒ½éªŒè¯æµ‹è¯• (2 tests)
    // ========================================================================

    #[test]
    fn test_performance_scaling() {
        let temp = create_wide_directory(200);

        let mut results = Vec::new();

        for thread_count in [1, 2, 4] {
            let config = ScanConfig {
                root: temp.path().to_path_buf(),
                include_files: true,
                thread_count,
            };

            let result = scan_parallel(&config).expect("æ‰«æå¤±è´¥");
            results.push((thread_count, result.duration));
        }

        // ä»…è®°å½•ï¼Œä¸æ–­è¨€
        println!("\næ€§èƒ½æ‰©å±•æµ‹è¯•ç»“æœ:");
        for (threads, duration) in &results {
            println!(
                "  {} çº¿ç¨‹: {:.3}ms",
                threads,
                duration.as_secs_f64() * 1000.0
            );
        }
    }

    #[test]
    fn test_reasonable_performance() {
        let temp = create_wide_directory(100);
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let result = scan_parallel(&config).expect("æ‰«æå¤±è´¥");

        // 100 ä¸ªæ–‡ä»¶ + 10 ä¸ªç›®å½•åº”è¯¥åœ¨ 1 ç§’å†…å®Œæˆ
        assert!(
            result.duration.as_secs() < 1,
            "æ‰«æè€—æ—¶è¿‡é•¿: {:?}",
            result.duration
        );
    }

    // ========================================================================
    // ä¸åŸç”Ÿ tree å‘½ä»¤å¯¹æ¯”æµ‹è¯• (1 test)
    // ========================================================================

    #[test]
    fn test_count_matches_native_tree() {
        let temp = create_test_directory();
        let config = ScanConfig {
            root: temp.path().to_path_buf(),
            include_files: true,
            thread_count: 4,
        };

        let our_result = scan_walk(&config).expect("æ‰«æå¤±è´¥");

        if let Ok(native) = scan_native_tree(temp.path(), true) {
            // åŸç”Ÿ tree ä¸è®¡å…¥æ ¹ç›®å½•
            let our_dirs = our_result.directory_count - 1;

            assert_eq!(
                our_dirs, native.directory_count,
                "ç›®å½•æ•°é‡ä¸åŒ¹é…: ours={}, native={}",
                our_dirs, native.directory_count
            );
            assert_eq!(
                our_result.file_count, native.file_count,
                "æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: ours={}, native={}",
                our_result.file_count, native.file_count
            );
        }
    }

    // ========================================================================
    // å¤§ç›®å½•æµ‹è¯•ï¼ˆä½¿ç”¨å®é™…è·¯å¾„ï¼‰
    // ========================================================================

    #[test]
    #[ignore]
    fn test_large_directory_rustup() {
        let rustup_path = PathBuf::from(r"C:\Users\linzh\.rustup");

        if !rustup_path.exists() {
            println!("è·³è¿‡: rustup è·¯å¾„ä¸å­˜åœ¨");
            return;
        }

        let config = ScanConfig {
            root: rustup_path.clone(),
            include_files: true,
            thread_count: num_cpus(),
        };

        println!("\næµ‹è¯•å¤§ç›®å½•: {:?}", rustup_path);

        let walk = scan_walk(&config).expect("walk æ‰«æå¤±è´¥");
        println!(
            "Walk: {} ç›®å½•, {} æ–‡ä»¶, {:.3}s",
            walk.directory_count,
            walk.file_count,
            walk.duration.as_secs_f64()
        );

        let parallel = scan_parallel(&config).expect("parallel æ‰«æå¤±è´¥");
        println!(
            "Parallel: {} ç›®å½•, {} æ–‡ä»¶, {:.3}s",
            parallel.directory_count,
            parallel.file_count,
            parallel.duration.as_secs_f64()
        );

        let report = verify_consistency(&walk, &parallel);
        println!("{}", report);

        assert!(report.is_consistent(), "å¤§ç›®å½•ä¸€è‡´æ€§éªŒè¯å¤±è´¥");
    }

    #[test]
    #[ignore]
    fn test_large_directory_consistency_stress() {
        let rustup_path = PathBuf::from(r"C:\Users\linzh\.rustup");

        if !rustup_path.exists() {
            return;
        }

        let config = ScanConfig {
            root: rustup_path,
            include_files: true,
            thread_count: num_cpus(),
        };

        let results: Vec<_> = (0..3)
            .map(|i| {
                let result = scan_parallel(&config).expect("æ‰«æå¤±è´¥");
                println!("è¿è¡Œ {}: {} æ¡ç›®", i, result.tree.collect_paths().len());
                result
            })
            .collect();

        for i in 1..results.len() {
            let report = verify_consistency(&results[0], &results[i]);
            assert!(report.is_consistent(), "å‹åŠ›æµ‹è¯•ç¬¬ {} æ¬¡è¿è¡Œä¸ä¸€è‡´", i);
        }
    }
}